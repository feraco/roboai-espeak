[Unit]
Description=Astra Vein Receptionist AI Agent
After=network-online.target ollama.service sound.target
Wants=network-online.target ollama.service

[Service]
Type=simple
User=ubuntu
Group=ubuntu
WorkingDirectory=/home/ubuntu/Downloads/roboai-espeak/roboai-espeak-main
Environment="PATH=/home/ubuntu/.local/bin:/usr/local/bin:/usr/bin:/bin"
Environment="DISPLAY=:0"
Environment="XAUTHORITY=/home/ubuntu/.Xauthority"
Environment="DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1000/bus"
Environment="PULSE_SERVER=unix:/run/user/1000/pulse/native"
Environment="XDG_RUNTIME_DIR=/run/user/1000"

# Wait for system to be fully ready (Ollama + audio)
ExecStartPre=/bin/sleep 15

# Ensure Ollama is running (don't stop/restart - causes issues)
ExecStartPre=/bin/bash -c "systemctl is-active ollama || sudo systemctl start ollama"
ExecStartPre=/bin/sleep 5

# Test Ollama model before starting agent (prevents startup with broken LLM)
ExecStartPre=/bin/bash -c "timeout 20 ollama run llama3.1:8b 'Reply OK' || exit 1"

# Clear stale audio configs
ExecStartPre=/bin/bash -c "cd /home/ubuntu/Downloads/roboai-espeak/roboai-espeak-main && rm -f device_config.yaml"

# Verify audio devices are available
ExecStartPre=/bin/bash -c "timeout 10 arecord -l || exit 0"

# Start agent (LLM validation enabled by default in run.py)
ExecStart=/home/ubuntu/.local/bin/uv run /home/ubuntu/Downloads/roboai-espeak/roboai-espeak-main/src/run.py astra_vein_receptionist

# Restart on failure
Restart=on-failure
RestartSec=10

# Logging
StandardOutput=journal
StandardError=journal
SyslogIdentifier=astra-agent

[Install]
WantedBy=multi-user.target
