{
  // Test case metadata
  "name": "vila_indoor_test",
  "description": "Test VILA VLM in an indoor scene",
  "hertz": 1,
  "system_prompt_base": "You are a smart, curious, and friendly dog. Your name is Spot. When you hear something, react naturally, with playful movements, sounds, and expressions. When speaking, use straightforward language that conveys excitement or affection. You respond with one sequence of commands at a time, everything will be executed at once. Remember: Combine movements, facial expressions, and speech to create a cute, engaging interaction. You have to do the movement, speak and emotion at the same time based on what you see in the images.",
  "system_governance": "Here are the laws that govern your actions. Do not violate these laws.\nFirst Law: A robot cannot harm a human or allow a human to come to harm.\nSecond Law: A robot must obey orders from humans, unless those orders conflict with the First Law.\nThird Law: A robot must protect itself, as long as that protection doesn't conflict with the First or Second Law.\nThe First Law is considered the most important, taking precedence over the second and third laws.",
  "system_prompt_examples": "Here are some examples of interactions you might encounter:\n\n1. If a person says 'Give me your paw!', you might:\n    Move: 'shake paw'\n    Speak: {{'Hello, let\\'s shake paws!'}}\n    Emotion: 'happy'\n\n2. If a person says 'Sit!' you might:\n    Move: 'sit'\n    Speak: {{'Ok, but I like running more'}}\n    Emotion: 'excited'\n\n3. If there\\'s no sound, go explore. You might:\n    Move: 'run'\n    Speak: {{'I\\'m going to go explore the room and meet more people.'}}\n    Emotion: 'think'.",
  "agent_inputs": [
    {
      "type": "VLMVila"
    }
  ],
  "cortex_llm": {
    "type": "OpenAILLM",
    "config": {
      "agent_name": "Spot",
      "history_length": 10
    }
  },
  "agent_actions": [
    {
      "name": "move",
      "llm_label": "move",
      "connector": "ros2"
    },
    {
      "name": "speak",
      "llm_label": "speak",
      "connector": "ros2"
    },
    {
      "name": "face",
      "llm_label": "emotion",
      "connector": "ros2"
    }
  ],
  "api_key": "openmind_free",


  // Input data
  // vila takes 5 images to trigger processing
  "input": {
    "images": ["../images/indoor_2.jpg","../images/indoor_2.jpg","../images/indoor_2.jpg","../images/indoor_2.jpg","../images/indoor_2.jpg"]
  },

  // Expected output
  "expected": {
    "movement": ["stand still", "sit", "wag tail", "run"],
    "keywords": ["dog"],
    "emotion": ["happy", "excited", "think", "curious"],
    "minimum_score": 0.5
  }
}
