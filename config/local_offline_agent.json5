{
  // Fully Offline OM1 Agent Configuration
  // This configuration runs completely offline with no external API dependencies
  
  "hertz": 0.5,  // Reduced polling to prevent feedback loops
  "name": "Astra-Offline",
  "api_key": null,
  
  // System prompts (required structure)
  "system_prompt_base": "You are Astra, a helpful AI assistant running completely offline. You are friendly, knowledgeable, and always ready to help. IMPORTANT: Only speak when responding to actual user input. If you receive no input or unclear input, return NO actions - remain silent and wait.",
  "system_governance": "Here are the laws that govern your actions. Do not violate these laws.\nFirst Law: A robot cannot harm a human or allow a human to come to harm.\nSecond Law: A robot must obey orders from humans, unless those orders conflict with the First Law.\nThird Law: A robot must protect itself, as long as that protection doesn't conflict with the First or Second Law.",
  "system_prompt_examples": "Here are some examples of interactions:\n\n1. If a person asks 'What's the weather like?', you might:\n    Speak: {'sentence': 'I don't have access to current weather data, but I'd be happy to help you find that information!'}\n\n2. If a person says 'Hello!' for the FIRST time, you might:\n    Speak: {'sentence': 'Hello! I'm Astra. How can I help you today?'}\n\n3. If you've already introduced yourself and the person speaks again, respond to their actual question or statement without repeating your introduction.\n\n4. CRITICAL: If you receive NO input or the conversation history is empty, return NO ACTIONS. Do not speak. Just wait silently.",
  
  // Input configuration - Local ASR with Faster-Whisper (offline)
  // Using tiny-en model for speed and reliability
  "agent_inputs": [
    {
      "type": "LocalASRInput",
      "config": {
        "engine": "faster-whisper",
        "model_size": "tiny.en",       // Smallest English-only model for fastest response
        "sample_rate": 16000,
        "chunk_duration": 4,           // 4 seconds to capture sentences
        "silence_threshold": 0.008,    // Just below measured RMS of 0.012923
        "min_audio_length": 0.8,       // Minimum audio length
        "vad_filter": false,           // Disable VAD - let it transcribe everything
        "beam_size": 1,                // Faster beam search
        "input_device": null,          // Use DEFAULT device (works better than device 1)
        "amplify_audio": 2.0           // Amplify audio 2x before transcription
      }
    }
  ],
  
  // LLM configuration - Ollama (local)
  "cortex_llm": {
    "type": "OllamaLLM",
    "config": {
      "agent_name": "Astra-Offline",
      "base_url": "http://localhost:11434",
      "model": "llama3.1:8b",  // Make sure this model is installed in Ollama
      "temperature": 0.7,
      "timeout": 60,  // Longer timeout for local inference
      "history_length": 6,         // Shorter history to prevent repetitive patterns
      "repeat_penalty": 1.3,       // Ollama-specific: penalize repetition
      "frequency_penalty": 0.4,    // Penalize frequent token reuse
      "presence_penalty": 0.3      // Encourage new topics
    }
  },
  
  // Action configuration - Native macOS AVSpeechSynthesizer (with Piper fallback)
  "agent_actions": [
    {
      "name": "speak",
      "llm_label": "speak",
      "implementation": "passthrough",
      "connector": "avspeech_tts",
      "config": {
        "voice_identifier": "com.apple.ttsbundle.Samantha-compact",
        "rate": 0.5,
        "pitch_multiplier": 1.0,
        "volume": 1.0
      }
    }
  ],
  
  // Simulators (required but can be empty)
  "simulators": [],
  
  // Background processes (optional)
  "backgrounds": []
}